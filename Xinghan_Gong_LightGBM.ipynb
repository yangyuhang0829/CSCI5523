{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import gc\n",
    "gc.enable() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('loading files ...')\n",
    "order_products_prior = pd.read_csv(PATH + 'order_products__prior.csv')\n",
    "order_products_train = pd.read_csv(PATH + 'order_products__train.csv')\n",
    "orders = pd.read_csv(PATH + 'orders.csv')\n",
    "products = pd.read_csv(PATH + 'products.csv', usecols=['product_id', 'aisle_id', 'department_id'])\n",
    "orders.eval_set = orders.eval_set.replace({'prior': 0, 'train': 1, 'test':2})\n",
    "orders.days_since_prior_order = orders.days_since_prior_order.fillna(30)\n",
    "print('done loading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_orders = pd.merge(orders, order_products_prior, on='order_id', how='inner')\n",
    "prior_orders.head()\n",
    "\n",
    "#deleting prior dataset\n",
    "del order_products_prior\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of orders placed by each user.\n",
    "users = prior_orders.groupby(by='user_id')['order_number'].aggregate('max').to_frame('u_num_of_orders').reset_index()\n",
    "# #converting the datatype to int.\n",
    "# users.u_num_of_orders = users.u_num_of_orders.astype(np.uint8)\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average products in orders placed by each users.\n",
    "\n",
    "#1. First getting the total number of products in each order.\n",
    "total_prd_per_order = prior_orders.groupby(by=['user_id', 'order_id'])['product_id'].aggregate('count').to_frame('total_products_per_order').reset_index()\n",
    "\n",
    "#2. Getting the average products purchased by each user\n",
    "avg_products = total_prd_per_order.groupby(by=['user_id'])['total_products_per_order'].mean().to_frame('u_avg_prd').reset_index()\n",
    "avg_products.head()\n",
    "\n",
    "#deleting the total_prd_per_order dataframe\n",
    "del [total_prd_per_order]\n",
    "gc.collect()\n",
    "\n",
    "avg_products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dow the user has ordered most.\n",
    "#importing the scipy's stats model\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "#execution will take approx 45sec.\n",
    "dow = prior_orders.groupby(by=['user_id'])['order_dow'].aggregate(lambda x : stats.mode(x)[0]).to_frame('dow_u_most_orders')\n",
    "#resetting the index\n",
    "dow = dow.reset_index()\n",
    "dow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hour of day the user has ordered most.\n",
    "\n",
    "#execution will take approx 45sec.\n",
    "hod = prior_orders.groupby(by=['user_id'])['order_hour_of_day'].aggregate(lambda x : stats.mode(x)[0]).to_frame('hod_u_most_orders')\n",
    "#resetting the index\n",
    "hod = hod.reset_index()\n",
    "hod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorder ratio of user.\n",
    "reorder_u = prior_orders.groupby(by='user_id')['reordered'].aggregate('mean').to_frame('u_reorder_ratio').reset_index()\n",
    "#changing the dtype.\n",
    "reorder_u['u_reorder_ratio'] = reorder_u['u_reorder_ratio'].astype(np.float16)\n",
    "reorder_u.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging users df and avg_prd\n",
    "users = users.merge(avg_products, on='user_id', how='left')\n",
    "#merging users df with dow\n",
    "users = users.merge(dow, on='user_id', how='left')\n",
    "#merging users df with hod\n",
    "users = users.merge(hod, on='user_id', how='left')\n",
    "#merging users df with reorder_u\n",
    "users = users.merge(reorder_u, on='user_id', how='left')\n",
    "\n",
    "\n",
    "#deleting unwwanted df\n",
    "del [reorder_u, dow, hod, avg_products]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of times purchased.\n",
    "prd = prior_orders.groupby(by='product_id')['order_id'].aggregate('count').to_frame('p_num_of_times').reset_index()\n",
    "# prd['p_num_of_times'] = prd['p_num_of_times'].astype(np.uint16)\n",
    "prd.head()\n",
    "\n",
    "#reordered ratio for each product\n",
    "reorder_p = prior_orders.groupby(by='product_id')['reordered'].aggregate('mean').to_frame('p_reorder_ratio').reset_index()\n",
    "# #changing dtype\n",
    "# reorder_p['p_reorder_ratio'] = reorder_p['p_reorder_ratio'].astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add to cart for each product.\n",
    "add_to_cart = prior_orders.groupby(by='product_id')['add_to_cart_order'].aggregate('mean').to_frame('p_avg_cart_position').reset_index()\n",
    "# #changing the dtype\n",
    "# add_to_cart['p_avg_cart_position'] = add_to_cart['p_avg_cart_position'].astype(np.float16)\n",
    "add_to_cart.head()\n",
    "\n",
    "#merging reorder_p with prd.\n",
    "prd = prd.merge(reorder_p, on='product_id', how='left')\n",
    "\n",
    "#merging add_to_cart with prd.\n",
    "prd = prd.merge(add_to_cart, on='product_id', how='left')\n",
    "\n",
    "#deleting unwanted df.\n",
    "del [reorder_p, add_to_cart]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#times a user have bough a product.\n",
    "uxp = prior_orders.groupby(by=['user_id', 'product_id'])['order_id'].aggregate('count').to_frame('uxp_times_bought')\n",
    "#resetting index\n",
    "uxp = uxp.reset_index()\n",
    "# #changing the dtype.\n",
    "# uxp['uxp_times_bought'] = uxp['uxp_times_bought'].astype(np.uint8)\n",
    "uxp.head()\n",
    "\n",
    "#times a user have bough a product.\n",
    "times = prior_orders.groupby(by=['user_id', 'product_id'])['order_id'].aggregate('count').to_frame('times_bought')\n",
    "#resetting index\n",
    "times = times.reset_index()\n",
    "# #changing the dtype.\n",
    "# times['times_bought'] = times['times_bought'].astype(np.uint8)\n",
    "times.head()\n",
    "\n",
    "#Total orders\n",
    "total_orders = prior_orders.groupby('user_id')['order_number'].max().to_frame('total_orders').reset_index()\n",
    "total_orders.head()\n",
    "\n",
    "#Finding when the user has bought a product the first time.\n",
    "first_order_num = prior_orders.groupby(by=['user_id', 'product_id'])['order_number'].aggregate('min').to_frame('first_order_num')\n",
    "#resetting the index\n",
    "first_order_num = first_order_num.reset_index()\n",
    "first_order_num.head()\n",
    "\n",
    "#merging both the dataframes\n",
    "span = pd.merge(total_orders, first_order_num, on='user_id', how='right')\n",
    "span.head()\n",
    "\n",
    "#Calculating the order range.\n",
    "# The +1 includes in the difference the first order were the product has been purchased\n",
    "span['Order_Range_D'] = span.total_orders - span.first_order_num + 1\n",
    "\n",
    "#merging times df with the span\n",
    "uxp_ratio = pd.merge(times, span, on=['user_id', 'product_id'], how='left')\n",
    "\n",
    "#calculating the ratio.\n",
    "uxp_ratio['uxp_reorder_ratio'] = uxp_ratio.times_bought / uxp_ratio.Order_Range_D\n",
    "\n",
    "#dropping all the unwanted columns.\n",
    "uxp_ratio.drop(['times_bought', 'total_orders', 'first_order_num', 'Order_Range_D'], axis=1, inplace=True)\n",
    "uxp_ratio.head()\n",
    "\n",
    "#deleting all the unwanted df.\n",
    "del [times, span, first_order_num, total_orders]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Merging all the created features into the uxp dataset.\n",
    "\n",
    "#merging uxp_ratio with uxp.\n",
    "uxp = uxp.merge(uxp_ratio, on=['user_id', 'product_id'], how='left')\n",
    "#deleting uxp_ratio\n",
    "del uxp_ratio\n",
    "#calling garbage collector.\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping only the train and test set from the orders df.\n",
    "orders_future = orders.loc[((orders.eval_set == 1) | (orders.eval_set == 2)), ['user_id', 'eval_set', 'order_id']]\n",
    "orders_future.head()\n",
    "\n",
    "#merging the orders_future with data.\n",
    "data = data.merge(orders_future, on='user_id', how='left')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing training data set.\n",
    "data_train = data[data.eval_set == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging the information contained in the order_products__train.csv into data_train.\n",
    "data_train = data_train.merge(order_products_train[['product_id', 'order_id', 'reordered']], on=['product_id', 'order_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling the NAN values in the reordered\n",
    "data_train.reordered.fillna(0, inplace=True)\n",
    "#setting user_id and product_id as index.\n",
    "data_train = data_train.set_index(['user_id', 'product_id'])\n",
    "\n",
    "#deleting eval_set, order_id as they are not needed for training.\n",
    "data_train.drop(['eval_set', 'order_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the test dataset.\n",
    "data_test = data[data.eval_set == 2]\n",
    "data_test.head()\n",
    "\n",
    "#setting user_id and product_id as index.\n",
    "data_test = data_test.set_index(['user_id', 'product_id'])\n",
    "\n",
    "#deleting eval_set, order_id as they are not needed for training.\n",
    "data_test.drop(['eval_set', 'order_id'], axis=1, inplace=True)\n",
    "\n",
    "#shape of train and test.\n",
    "data_train.shape, data_test.shape\n",
    "\n",
    "#deleting unwanted df and collecting garbage\n",
    "del [data, orders_future, products, order_products_train]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from scikitplot.metrics import plot_confusion_matrix\n",
    "from scikitplot.classifiers import plot_feature_importances\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating X and y variables.\n",
    "X = data_train.drop('reordered', axis=1)\n",
    "y = data_train.reordered\n",
    "\n",
    "#splitting dataset into train and test split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a light gradient boosting model.\n",
    "# #Initializing the model\n",
    "lgbm = lgb.LGBMClassifier(objective='binary', num_leaves=96, max_depth=10)\n",
    "\n",
    "#fitting the model.\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "#prediction\n",
    "y_pred = (lgbm.predict_proba(X_test)[:, 1] >= 0.21).astype('int') #setting a threshold.\n",
    "\n",
    "#Evaluation.\n",
    "print('F1 Score: {}'.format(f1_score(y_pred, y_test)))\n",
    "print(classification_report(y_pred, y_test))\n",
    "plot_confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting on entire data.\n",
    "lgbm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making prdeictions on the test dataset\n",
    "y_pred_test = (lgbm.predict_proba(data_test)[:, 1] >= 0.21).astype('int') #setting a threshold.\n",
    "\n",
    "#saving the prediction as a new column in data_test\n",
    "data_test['prediction'] = y_pred_test\n",
    "\n",
    "# Reset the index\n",
    "final = data_test.reset_index()\n",
    "# Keep only the required columns to create our submission file (for chapter 6)\n",
    "final = final[['product_id', 'user_id', 'prediction']]\n",
    "\n",
    "gc.collect()\n",
    "final.head()\n",
    "\n",
    "#Creating a submission file\n",
    "orders = pd.read_csv(PATH + 'orders.csv')\n",
    "orders_test = orders.loc[orders.eval_set == 'test', ['user_id', 'order_id']]\n",
    "orders_test.head()\n",
    "\n",
    "#merging our prediction with orders_test\n",
    "final = final.merge(orders_test, on='user_id', how='left')\n",
    "\n",
    "#remove user_id column\n",
    "final = final.drop('user_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert product_id as integer\n",
    "final['product_id'] = final.product_id.astype(int)\n",
    "\n",
    "## Remove all unnecessary objects\n",
    "del orders\n",
    "del orders_test\n",
    "gc.collect()\n",
    "\n",
    "d = dict()\n",
    "for row in final.itertuples():\n",
    "    if row.prediction== 1:\n",
    "        try:\n",
    "            d[row.order_id] += ' ' + str(row.product_id)\n",
    "        except:\n",
    "            d[row.order_id] = str(row.product_id)\n",
    "\n",
    "for order in final.order_id:\n",
    "    if order not in d:\n",
    "        d[order] = 'None'\n",
    "        \n",
    "gc.collect()\n",
    "\n",
    "#We now check how the dictionary were populated (open hidden output)\n",
    "#d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the dictionary into a DataFrame\n",
    "sub = pd.DataFrame.from_dict(d, orient='index')\n",
    "\n",
    "#Reset index\n",
    "sub.reset_index(inplace=True)\n",
    "#Set column names\n",
    "sub.columns = ['order_id', 'products']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('sub.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
